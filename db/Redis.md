[TOC]

# 总览

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/db/redis/1.redis-全局脉络.png">

<img src="/Users/nieguanglin/docs/pics/db/redis/1.redis-全局脉络.png" alt="1.redis-全局脉络.png" style="zoom:100%;" />

# 应用维度

## 缓存应用

### 缓存的类型

**只读缓存**

- 读请求：查Redis，存在，直接返回；不存在，查数据库，并更新缓存，再返回。
- 写请求：直接写入数据库。查Redis，存在，删除缓存，再返回；不存在，直接返回。

读写缓存

- 读请求：与只读缓存相同。
- 写请求：既写入缓存，也写入数据库。

### 淘汰策略

- noeviction：不进行数据淘汰。

  Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据。一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。

无论是volatile还是allkeys，只要过期时间到，就会进行淘汰。另外，一旦内存使用到达阈值，也会根据下面的具体策略进行淘汰。

- 在已经设置了过期时间的数据中
  - volatile-random
  - volatile-ttl：根据过期时间的先后进行删除，越早过期的越先被删除。
  - volatile-lru
  - volatile-lfu
- 在所有的数据中
  - allkeys-random
  - allkeys-lru
  - allkeys-lfu

**LRU**

Least Recently Used（最近最少使用），最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。

**LFU**

Least Frequently Used，在筛选数据时，**首先会筛选并淘汰访问次数少的数据**，然后针对访问次数相同的数据，再**筛选并淘汰访问时间最久远的数据**。

- 为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数据的访问次数。

- 在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制。




### 缓存数据不一致

- 其中一个报错：

（无论是只读缓存，还是读写缓存）要在业务应用中使用事务机制，来保证缓存和数据库的更新具有原子性，也就是说，两者要不一起更新，要不都不更新，返回错误信息，进行重试。

**删除缓存值或更新数据库失败而导致数据不一致，可以使用重试机制确保删除或更新操作成功。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。**

- 都不报错，但是有多个线程并发：

  - 只读缓存，先更新数据库，再更新缓存：由于更新数据库慢而更新缓存快，所以造成的结果影响较小。

    所以它才是只读缓存正确的更新顺序。

  - 只读缓存，先更新缓存，再更新数据库：如果不采取特殊措施，会导致数据不一致，并且持续较长时间。

    更新线程要进行”延迟双删“——在更新完数据库值以后，让它先 sleep 一小段时间，再进行一次缓存删除操作。

### 缓存雪崩

缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。

原因：

- 缓存中有大量数据同时过期，导致大量请求无法得到处理。——避免给大量的数据设置相同的过期时间，给数据的过期时间增加一个较小的随机数。
- Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层。

### 缓存穿透

缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中。导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。就会同时给缓存和数据库带来巨大压力。

原因：

- 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据。
- 恶意攻击：专门访问数据库中没有的数据。——可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。

​	



## 集群应用

## 数据结构应用



# 系统维度

## 高性能主线

### 线程模型

Redis 是单线程，主要是指 Redis 的**网络 IO 和键值对读写**是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。

但 Redis 的其他功能，比如**持久化、异步删除、集群数据同步**等，其实是由额外的线程执行的。



为什么单线程？

- 并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。
- 而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。

为了避免这些问题，Redis 直接采用了单线程模式。



为什么那么快？通常来说，单线程的处理能力要比多线程差很多，但是 Redis 却能使用单线程模型达到每秒数十万级别的处理能力，这是为什么呢？

其实，这是 Redis 多方面设计选择的一个综合结果。

- 一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。
- 另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。



### 数据结构

键和值用哈希表来组织，称为全局哈希表。

哈希表的时间复杂度是O(1)——》会有哈希冲突，采用链表法来解决冲突——》链表过长会影响性能，设定装载因子，超过阈值会扩容——》大量的copy会阻塞系统，采用延迟copy。



值的数据类型和底层数据结构的对应。

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/db/redis/2.redis-value数据类型与底层实现类型.png">

<img src="/Users/nieguanglin/docs/pics/db/redis/2.redis-value数据类型与底层实现类型.png" alt="2.redis-value数据类型与底层实现类型.png" style="zoom:100%;" />

- 压缩列表

  压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。

  在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

  压缩列表的设计不是为了查询的，而是为了减少内存的使用和内存的碎片化。比如一个列表中的只保存int，结构上还需要两个额外的指针prev和next，每添加一个结点都这样。而压缩列表是将这些数据集合起来只需要一个prev和next。

- 跳表



### AOF

Append Only File，不同于WAL，Redis先把数据写入内存，然后再记录AOF日志。AOF 日志也是在主线程中执行的。

日志内容

传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。

```
# 以"et testkey testvalue"为例
*3
$3
set
$7
testkey
$9
testvalue
```



"写后"日志

为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令。



写回策略

配置项appendfsync的三个可选值。

- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。



重写机制

和 AOF 日志由主线程写回不同，重写过程是由**后台子进程** bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

AOF 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。也即，AOF文件会变小。



### RDB

Redis DataBase，就是把某一时刻的内存状态以文件的形式写到磁盘上，即快照。

和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，可以直接把 RDB 文件读入内存，很快地完成恢复。



是否阻塞主线程

- save命令：在主线程中执行，会导致阻塞；
- bgsave命令：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。



开销

- 数据落盘的IO开销。频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
- fork系统调用的开销。bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）。



RDB与AOF混合使用

内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

- 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；
- 如果允许分钟级别的数据丢失，可以只使用 RDB；
- 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。



### epoll网络框架

Linux 中的 IO 多路复用机制是指**一个线程处理多个 IO 流**，就是我们经常听到的 select/epoll 机制。在 Redis 只运行单线程的情况下，同时存在多个套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。



所谓请求到达对Redis线程的“通知”，其实就是select/epoll 提供的基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。

那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。



举例

以连接请求和读数据请求为例。这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。



## 高可用主线

### 主从复制

全量复制

- 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。
- 在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。
- 第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。



基于长连接的命令传播

一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。



增量复制

长连接如果遇到了网络断连，增量复制就派上用场了。

repl_backlog_size 这个配置参数，如果配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。



### 哨兵机制



## 高可扩展主线

### 数据分片

### 负载均衡