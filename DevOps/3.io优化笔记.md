[TOC]

# 磁盘性能指标

## 使用率

磁盘处理i/o的时间百分比。过高的使用率（比如超过80%），通常因为着磁盘i/o存在性能瓶颈。（使用率只考虑有没有 I/O，而不考虑 I/O 的大小。当使用率100%时，磁盘依然有可能接受新的i/o请求。）

## 饱和度

磁盘处理i/o的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度100%时，磁盘无法接受新的i/o请求。

## IOPS

Input/Output Per Second，每秒i/o请求数。

## 吞吐量

每秒i/o请求大小。

## 响应时间

i/o请求从发出，到收到响应的间隔时间。



# 案例

## 定位引发i/o瓶颈的进程

### top

cpu方面，其中一个cpu的系统cpu使用率sy为6%，而等待i/ocpu使用率wa超过了90%，**推测**该cpu上可能正在运行i/o密集型的进程。

mem方面，剩余内存很小，而buff/cache占用内存很高，这说明内存主要被缓存占用。至于缓存的使用是否合理，需要进一步观察。

进程部分，cpu使用率%CPU都不大，观察不到明显异常。

### iostat

```bash
$ iostat -d -x 1
```

-d：显示i/o性能指标

-x：显示扩展统计

输出的结果，字段说明如下：

| 字段     | 含义                                        | 补充                                                         |
| -------- | ------------------------------------------- | ------------------------------------------------------------ |
| r/s      | 读请求数。                                  | 合并后的请求数。                                             |
| w/s      | 写请求数。                                  | 合并后的请求数。**r/s+w/s，即为IOPS。**                      |
| rkB/s    | 读数据量。                                  |                                                              |
| wkB/s    | 写数据量。                                  | **rkB/s+wkB/s，即为吞吐量。**                                |
| rrqm/s   | 合并的读请求数。                            | %rrqm表示合并读请求的百分比。                                |
| wrqm/s   | 合并的写请求数。                            | %wrqm表示合并写请求的百分比。                                |
| r_await  | 读请求处理完成的等待时间。                  | 包括队列中的等待时间和设备实际处理的时间，单位ms。           |
| w_await  | 写请求处理完成的等待时间。                  | 包括队列中的等待时间和设备实际处理的时间，单位ms。**r_await+w_await，即为响应时间。** |
| aqu-sz   | 平均请求队列长度。                          |                                                              |
| rareq-sz | 平均读请求大小。                            | 单位kB。                                                     |
| wareq-sz | 平均写请求大小。                            | 单位kB。                                                     |
| svctm    | 处理i/o请求所需的平均时间，不包括等待时间。 | 单位ms。                                                     |
| %util    | 磁盘处理i/o的时间百分比。                   | **即使用率**，由于可能存在并行i/o，100%并不一定表明磁盘i/o饱和。 |

其中一个磁盘的使用率%util非常高，很可能已经接近i/o饱和。

每秒写请求数w/s 60多，每秒写数据量wkB/s 32000kB左右，写请求多响应时间w_await 7000ms左右，平均请求队列长度aqu-sz 1000左右。慢的响应时间和长的请求队列，进一步验证i/o已经饱和的猜想。前面iowait高达90%，正是该磁盘严重的性能瓶颈引起的。

### pidstat

```bash
$ pidstat -d 1
```

-d：显示进程的i/o情况。

输出的结果中：

- **kB_rd/s**：每秒读取的数据大小。
- **kB_wr/s**：每秒发出的写请求数据大小。
- kB_ccwr/s：每秒取消的写请求数据大小。
- **iodelay**：块i/o延迟，包括等待同步块i/o和换入块i/o结束的时间，单位是时钟周期。

某个app进程的每秒写数据大小超过40000kB，应该就是它导致了i/o饱和。

此外，内核线程kworker和jbd2的iodelay比该app还要大。jbd2是ext4文件系统中用来保证数据完整性的内核线程。它们都是保证文件系统基本功能的内核线程，延迟的根源还是大量i/o。

### lsof

用来查看进程打开的文件列表。文件不只包含普通文件，还包括目录，块设备，动态库，网络socket等。

```bash
$ lsof -p $pid
```

可以发现，该app打开了一个日志文件，SIZE非常大。

检查该app的源码，发现它在线上仍然把日志级别设置为debug，而且日志信息非常长。

## SQL查询耗时严重

定位app的过程和上面的例子差不多。都是top发现cpu使用率没有什么异常；iostat发现i/o使用率很高，确定是i/o瓶颈；最后通过pidstat定位到app，这次发现app是mysqld。

### strace

```bash
$ strace -f -p $pid
```

MySQL是一个多线程的数据库应用，所以为了不漏掉这些线程的数据读取情况，要加上-f参数。

输出的结果显示，pid为xxx的线程正在读取大量数据，且文件描述符为38。

### lsof

此时，lsof没有输出任何信息。使用$?查询上一条命令退出时的返回值，发现不是0。也就是说lsof执行失败。原因在于，strace输出的pid只是一个线程号，而lsof -p需要的是进程号。

正确输入pid后，发现38号文件描述符对应的文件是：/var/lib/mysql/$database_name/$table.MYD。MYD文件是MyISAM引擎用来存储表数据的文件，文件名就是数据表的名字，该文件的父目录就是数据库的名字。

```bash
$ docker exec -it $container_name mysql
mysql> show full processlist;
```

输出的结果中，Info包含了完整的SQL语句，大概为：select * from $database_name where key=xxx。

排查该表的结构，发现它并不包含key的索引。所以这条语句查询时，会扫描全表，响应就特别慢。

## Redis响应延迟严重

观察top的输出发现，cpu的iowait比较高，而各个进程的cpu使用率都不太高。剩余内存也还有很多。综合top的信息，比较有嫌疑的就是iowait。

观察iostat的输出，磁盘wkB/s为几mB，%util却很低。虽然有些i/o操作，但并没有导致磁盘的i/o瓶颈。

当前的系统中，app与数据库之间，有一个缓存层Redis。app的查询接口响应延迟严重，对于查询，对应的i/o应该是磁盘的读操作。虽然系统i/o没有出现性能瓶颈，但是iostat输出的磁盘写也是比较奇怪的。

观察pidstat的输出，发现redis-server正在进行磁盘写。

### strace

```bash
$ strace -f -T -tt -p $pid
```

-f：跟踪子进程和子线程。

-T：显示系统调用时长。

-tt：显示跟踪时间。

输出的结果中，epoll_pwait，read，write，fdatasync系统调用比较频繁。iostat观察到的写磁盘，应该就是write或fdatasync导致的。接着再通过lsof和文件描述符，找出这些系统调用的操作对象。

一个普通文件appendonly.aof，相应的系统调用包括write和fdatasync，它才会产生磁盘写。

> redis提供了两种数据持久化的方式，分别是快照和追加文件。
>
> 快照
>
> 会按照指定的时间间隔，生成数据的快照并落盘。为了避免阻塞主进程，redis还会fork出一个子进程，来负责快照的保存。这种方式性能好，无论备份还是恢复，都比追加文件的方式好。但缺点也很明显。数据量大的时候，fork子进程需要用到比较大的内存，保存数据也很耗时。所以一般时间间隔较长，比如5分钟。这样即使发生故障，丢失的就是这几分钟的数据。
>
> 追加文件
>
> 在文件末尾追加记录的方式，对redis写入的数据，依次进行持久化。配置文件中用appendfsync设置fsync的策略。
>
> - always：每次操作都会调用一次fsync，最为安全。
> - everysec：每秒都会调用一次fsync，这样保证最坏情况下，丢失1秒的数据。
> - no：不调用fsync，交给操作系统处理。

查看配置文件，appendfsync配置的always。正是大量的fsync产生了大量i/o，这个配置项确实不合理。

那为什么一个查询接口，会产生大量的磁盘写呢？查看该app的源码，最终发现代码中把redis当成了临时空间，用来存储查询过程中找到的数据。这些数据放在内存中就可以了，没必要再通过网络调用存储在redis中。也就是说，app在滥用redis。



# Index

## iostat

磁盘i/o使用率，IOPS，吞吐量，响应时间，i/o平均大小，等待队列长度。

## pidstat

进程i/o大小以及i/o延迟。



## sar*

磁盘i/o使用率，IOPS，吞吐量，响应时间。

## dstat*

-d：磁盘i/o使用率，IOPS，吞吐量



## iotop

按i/o大小对进程排序。

```bash
$ iotop
```

输出的结果中：

- Total Disk READ：磁盘读总数。

- Total Disk WRITE：磁盘写总数。

- Actual Disk READ：磁盘真实的读总数。

- Actual Disk WRITE：磁盘真实的写总数。

  > 因为缓存，缓冲区，i/o合并等因素，它们可能并不相等。

- PRIO：i/o优先级。

- DISK READ：每秒读磁盘的大小。

- DISK WRITE：每秒写磁盘的大小。

- SWAPIN：换入的时钟百分比。

- IO>：等待i/o的时钟百分比。

## slabtop，/proc/slabinfo

inode，dentry，文件系统的缓存。



## vmstat

缓存和缓冲区用量汇总。

## strace

跟踪进程的i/o系统调用。



## df

磁盘空间和索引节点使用量和剩余量。

## du

目录占用的磁盘空间大小。

