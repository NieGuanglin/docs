[TOC]

# 总览

关于操作系统的内存管理，主要有三个方面，其中虚拟内存是重点：

1. 程序所使用的内存地址叫**虚拟内存地址**。
2. 实际存在硬件里面的空间地址叫**物理内存地址**。
3. 虚拟内存到物理内存的映射。

虚拟地址空间分用户态和内核态，这就衍生出四个角度：

1. 进程视角看用户态地址空间

   每个进程都觉得自己是独享内存的，因为在当前CPU的cr3寄存器里面指向的是这个进程的页表，因而这个进程的代码无论访问哪个地址，硬件一转换，都只落在属于这个进程的物理内存中。

2. 进程视角看内核态地址空间

   虽然知道地址在哪，但是访问不到。需要通过系统调用进入内核，再访问。

3. 内核视角看用户态地址空间

   虽然内核的权限足够访问所有的物理内存，所有进程的页表也在内存里面，内核都有权限访问。但是对于用户态虚拟地址却无从下手。因为在内核态cr3里面的是内核的页表。

4. 内核视角看内核态地址空间

   内核里面访问内存大部分情况下还是使用虚拟地址。因为内核也有自己的页表，内核页表是独一份的，内核的页表仅仅覆盖内核地址空间的部分，内核的数据都放在这部分虚拟地址空间里面。一旦进入内核，CPU的cr3就指向了内核的页表，同样是硬件一转换，就落在了属于内核的物理内存中。

查看进程内存空间的布局：

```bash
$ pmap $PID

$ cat /proc/$PID/maps 
```

## 系统调用

x86提供了分层的权限机制，把区域分为四个Ring。Linux很好的利用了这个机制，把能够访问关键资源的代码放在Ring0，即为内核态；把普通的程序代码放在Ring3，即为用户态。所以，系统调用就是操作系统提供的，用户态与内核态交互的一组接口。

有三种方式使用系统调用：

1. 通过glic封装的api。
2. 32位系统通过软中断指令 int 0x80陷入内核态。
3. 64位系统通过syscall。

系统调用的过程：

1. 先保存用户态寄存器到内核空间的pt_regs；
2. 在系统调用表里，根据系统调用号找到系统调用函数，执行；
3. 恢复用户态寄存器，返回用户态。



# 虚拟内存

操作系统负责将不同进程的虚拟地址和不同内存的物理地址映射起来，并且给每个进程分配一套独立的虚拟地址。进程不直接访问物理地址，它只访问虚拟地址。这样就可以让物理内存支持同时运行多个程序。

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/1%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E6%80%BB%E8%A7%88.png">

对于32位系统，最大能够寻址2^32 B = 4GB，其中用户态3GB，内核态1GB。

对于64位系统，虚拟地址只使用了48位。1左移47位，就相当于48位地址空间一半的大小，0x0000 8000 0000 0000，然后减去一个页4KB（0x1000），就是0x0000 7FFF FFFF F000，共128T（这个计算过程，可以类比为将8位二进制数一分为二，求下半部的上限位置。即，1左移7位，128就相当于8位地址空间一半的大小，0x80，然后减去1，就是0x7F，共128bit）。内核空间和用户空间之间隔着很大的空隙，以此来隔离。

## 用户空间

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/2%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80-%E7%94%A8%E6%88%B7%E6%80%81.png">

- text：存放编译好的二进制可执行代码。
- data：存放已初始化数据，包括静态常量。
- bss：存放未初始化数据，包括未初始化的静态变量。
- heap堆：malloc分配的小块内存在堆里面（brk系统调用）。
- mmp内存映射区：用于匿名映射中的swap区映射；文件映射；动态链接库。malloc分配的大块内存在mmp里面（mmp系统调用）。
- stack栈：函数调用链以及函数运行期间产生的局部变量和调用参数。栈的大小默认8MB。

## 内核空间

**内核态的虚拟空间和某一个进程没有关系，所有进程通过系统调用进入到内核后，看到的虚拟地址空间都是一样的。**

### 32位系统

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/3%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80-32%E4%BD%8D%E5%86%85%E6%A0%B8%E6%80%81.png">

- 直接映射区：所谓直接映射区，就是这一块空间是连续的，和物理内存是非常简单的映射关系，其实就是虚拟内存地址减去3GB，得到物理内存的位置。
  - 在系统启动的时候，物理内存前1MB已经被占用。
  - 从1MB开始加载内核代码段，已初始化的静态常量，未初始化的静态变量等。
  - 创建进程时，创建的task_struct实例，也在直接映射区。
  - 内核栈的分配，也在直接映射区。

- vmalloc区：VMALLOC_START到VMALLOC_END之间称为内核动态映射空间，也即内核想要像用户态进程一样malloc申请内存，在内核里面可以使用vmalloc。


- 持久映射区：PKMAP_BASE到FIXADDR_START的空间称为持久内核映射。


- 固定映射区：FIXADDR_START到FIXADDR_TOP(0xFFFF F000)的空间，称为固定映射区。


- 最后一个区域：在最后一个区域可以通过kmap_atomic实现临时内核映射。假设用户态进程要映射一个文件到内存中，先要映射用户态进程空间的一段虚拟地址到物理内存，然后将文件内容写入这个物理内存供用户态进程访问。但是如果要把文件内容写入物理内存，只能借助系统调用和内核空间，于是就通过kmap_atomic做一个临时映射，写入物理内存完毕后，再kunmap_atomic来解映射。


### 64位系统

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/4%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80-64%E4%BD%8D%E5%86%85%E6%A0%B8%E6%80%81.png">

- 从0xFFFF 8000 0000 0000开始就是内核的部分，一开始有8T的空档区域。
- 从_PAGE_OFFSET_BASE(0xFFFF 8800 0000 0000)开始的64T的虚拟地址空间是直接映射区。

- 从VMALLOC_START(0xFFFF C900 0000 0000)开始到VMALLOC_END(0xFFFF E900 0000 0000)的32T的空间是给vmalloc的。


- 从VMEMMAP_START(0xFFFF EA00 0000 0000)开始的1T空间用于存放物理页面的描述结构struct page。


- 从_START_KERNEL_map(0xFFFF FFFF 8000 0000)开始的512MB用于存放内核代码，已初始化的静态常量，未初始化的静态变量等。


## 内存分段

内存空间是由若干个逻辑分段组成的，比如可由代码段、数据段、栈段、堆段组成。用分段（Segmentation）的形式把这些段分离出来。

分段模式下，虚拟地址与物理地址通过段表进行映射。通过段选择子和段内偏移量的组合来寻址。段选择子中的段号，可以在段表中查到该段的段基地址，再加上段内偏移量，就可以定位物理内存地址。

但是分段有如下缺点：

- 内存碎片。

  - 外部内存碎片，每个段的大小都不是统一的，也就是容易产生多个不连续的小物理内存，导致新的程序无法被装载。
  - 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费。

- 内存交换的效率低。

  为了解决内存碎片的问题，支持运行更多的进程，这就需要内存交换。即swap，把内存中的数据换出到硬盘，需要时再从硬盘换入到内存。这个过程会调整内存中数据的位置，尽量形成大块的连续内存，以支持运行新进程。但是这又带来一个新问题：内存交换的效率低。因为硬盘的访问速度要比内存慢太多了，每一次内存交换，都需要把一大段连续的内存数据写到硬盘上。

其实，**分段模式带来的种种缺点的根本原因就是内存管理的粒度太大，以段为粒度不够精细**。

## 内存分页

把整个虚拟和物理内存空间切成一个个固定尺寸的单位，这些单位称为页（Page)，在Linux中，每一页的大小为4KB。

虚拟内存与物理内存通过页表进行映射，即页号在页表中找到页基地址，再加上页内偏移，就可以定位物理内存。

分页解决分段的内存碎片，内存交换效率低的问题：

- 由于内存空间都是预先划分好的，也就不会像分段那样产生间隙非常小的内存。
- 内存交换时，以页为单位，不会花太多时间，效率就比较高。
- 分页的方式使得在程序运行中，只有真的需要对应虚拟内存页里面的指令和数据时，再从磁盘加载到物理内存中去。更进一步地减少了可能需要交换的数据量。

简单分页模式的缺陷：

空间的缺陷，32位的环境下，虚拟地址共4GB（2^2 * 2^30 byte），每个页的大小为4KB（2^2 * 2^10 byte），所以就需要1M（2^20）个页表项。每个页表项占用4Byte，所以每个页表共需要4MB大小的空间来存储。如果进程数多的话，就需要相当大的内存了，更别说64位的环境了。

多级页表：

在实际的系统中，会采用多级页表的方式。上级页目录表会保存下级页目录表的基地址，下级页目录表会保存下下级页目录表的基地址，层层递归下去，最后一级页目录表会保存页的基地址，再加上页内偏移，就可以定位物理内存。

理论上，多级页表会占用更多内存，但实际上，很多没有使用的页表根本就没有创建，所以多级页表更节省内存。

多级页表中，只需要最高级页目录表覆盖整个虚拟地址空间。实际没有使用的页表，可以不用创建。这样就大大的节省空间了。而且，进程实际使用到的内存远远未达到全部虚拟地址。那为什么不分级的页表就做不到这样的内存节约呢？从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。所以页表一定要覆盖整个虚拟地址空间，不分级的页表就需要1M个页表项，而分级的页表只需要最高级的页表覆盖虚拟地址即可。

64位系统的多级页表：

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/5%E5%9B%9B%E7%BA%A7%E7%9B%AE%E5%BD%95.png" />

1. 全局页目录项PGD，Page Global Directory
2. 上层页目录项PUD，Page Upper Directory
3. 中间页目录项PMD，Page Middle Directory
4. 页表项PTE，Page Table Entry

由于x86_64处理器硬件限制，地址总线只有48位，所以硬件要求传入的地址48到63位地址必须相同。4KB页面下，48位地址分为5段，位宽分别是9，9，9，9，12。

### HugePages

页越大，一个页表项就能表示越多的地址空间，整个TLB缓存命令的几率就越大。

但是同时，就越容易产生大量的内部碎片，造成内存浪费。

```shell
$ cat /proc/meminfo | grep Huge
HugePages_Total: 0
HugePages_Free: 0
HugePages_Rsvd: 0
HugePages_Surp: 0
Hugepagesize: 2048 kB
```

- HugePages_Total：系统当前总共拥有的HugePages数目。


- HugePages_Free：系统当前总共拥有的空闲HugePages数目。


- HugePages_Rsvd：系统当前总共保留的HugePages数目，更具体指程序已经向系统申请，但是由于程序还没有实质的HugePages读写操作，因此系统尚未实际分配给程序的HugePages数目。


- HugePages_Surp：超过系统设定的常驻HugePages数目的数目。


- Hugepagesize：每页HugePages的大小。


```shell
$ cat /proc/sys/vm/nr_hugepages
0
$ cat /proc/sys/vm/nr_hugepages_mempolicy
0
$ cat /proc/sys/vm/nr_overcommit_hugepages
0
```

- /proc/sys/vm/nr_hugepages：用于设定系统拥有的常驻HugePages数目的/proc接口。


- /proc/sys/vm/nr_hugepages_mempolicy：与/proc/sys/vm/nr_hugepages的作用类似，但它只出现在NUMA系统上，用于更精细的HugePages申请分配（比如指定NUMA节点，来分配HugePages）。


- /proc/sys/vm/nr_overcommit_hugepages：表示程序申请HugePages可超过常驻HugePages数目的最大数目。


## 内存管理

由于x86架构的历史原因，分页模式是建立在分段模式的基础上的。段式内存管理单元负责：将段的**逻辑地址**，转换为**虚拟地址**。页式内存管理单元负责：将**虚拟地址**，转换为**物理地址**。 x86架构一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。

Linux作为操作系统软件，主要采用的是页式内存管理，但同时不可避免地涉及了段机制。实际上，Linux内核所采取的办法是使段式映射的过程实际上不起什么作用。每个段都是从0地址开始的整个虚拟地址，也就是说所有段的起始地址都是一样的。这就意味着，程序代码所面对的地址空间都是虚拟地址，屏蔽了处理器中的逻辑地址概念。**段只被用于访问控制和内存保护。段表中有段基址，段界限和特权等级（DPL）。用户态DPL是3，内核态DPL是0。当用户态试图访问内核态时，会因为权限不足而报错。**



# 物理内存

## SMP

SMP（Symmetric multiprocessing）对称多处理器：CPU是通过总线去访问内存，CPU会有多个，在总线的一侧。所有的内存条组成一大片内存，在总线的另一侧。所有的CPU访问内存都要经过总线。这种模式有一个显著的缺点，就是总线会成为瓶颈，因为访问数据都要通过它。

## NUMA

### Node

NUMA（Non-Uniform Memory Access）非一致内存访问：在这种模式下，内存不是一整块。每个CPU都有自己的本地内存，CPU访问本地内存不用通过总线，因而速度要快很多。每个CPU和内存在一起，称为一个node。在本地内存不足的情况下，CPU可以去另外的node申请内存，这个时候的访问延时就会比较长。

### Zone

每个节点分成多个区域zone：

- ZONE_DMA：可用作DMA（Direct Memory Access，直接内存存取）的内存。要把外设的数据读入内存或把内存的数据传送到外设，原来都需要cpu控制完成，但这会占用cpu，影响cpu处理其他事情。在DMA模式下，cpu只需向DMA控制器下达指令，让它来处理数据的传送，数据传送完毕再把信息反馈给cpu，这样就解放了cpu。
- ZONE_DMA32
- ZONE_NORMAL：直接映射区。从物理内存到虚拟内存的内核区域，通过加上一个常量直接映射。
- ZONE_HIGHMEM：高端内存。对于32位系统来说超过896M的地方。
- ZONE_MOVAVLE：可移动区域。通过将物理内存划分为可移动分配区域和不可移动分配区域来避免内存碎片。

## 内存分配的方式

### 整页内存分配

通过**伙伴系统**（Buddy System），分配内存。Linux把所有的空闲页分组为11个页块链表，每个链表分别包含多个页块。比如第一个链表的页块大小为1个页，第二个为2，第三个为4，第十一个为1024。

例如，要请求一个128个页的页块时，先检查128个页的页块链表是否有空闲块。如果没有，则检查256个页的页块链表；如果有，则把256个页的页块分成两份，一份使用，一份插入128个页的页块链表中。如果还没有，就检查512个页的页块链表；如果有，就分裂为128，128，256三个页块，一个128的使用，剩余两个插入对应页块链表。

- Anonymous Pages 匿名页：直接和虚拟地址空间建立映射关系。
- Memory-mapped File 内存映射文件：物理内存先关联一个文件，然后再和虚拟地址空间建立映射关系。

### 小块内存分配

- slab allocator：用于分配称为slab的一小块内存。它向伙伴系统申请大的内存块，然后划分成多个小块的存储池，用复杂的队列来维护这些小块的状态。
- slub allocator：不使用队列的分配器slub allocator，可以看成slab allocator的另一种实现。
- slob：用于小型的嵌入式系统。

## SWAP

每个进程都有自己的虚拟地址空间，无论32位还是64位，虚拟地址空间都非常大，物理内存不可能有这么多的空间放得下。所以，一般情况下，页面只有在被使用的时候，才会放在物理内存中。如果过了一段时间不被使用，即使用户进程并没有释放它，物理内存管理也有责任做一定的干预。比如，将这些物理内存中的页面换出到硬盘上，空出的物理内存，交给活跃的进程去使用。

页面换出时，对于匿名页来说，需要分配swap，将内存页写入文件系统；对于内存映射关联了文件的，需要将在内存中对于文件的修改写回到文件中。

**页面的换入换出是物理内存的管理部分，对虚拟内存透明，虚拟内存使用的时候，是假设页面一定在的，意识不到换入换出的问题。**



# 虚拟内存与物理内存映射

## 内存映射

用户进程在运行的过程中，访问虚拟内存中的数据，会被cr3里面指向的页表转换为物理地址后，才在物理内存中访问数据，这个过程都是在用户态运行的，地址转换的过程无需进入内核态。

只有访问虚拟内存的时候，发现没有映射到物理内存，页表也没有创建，才会触发缺页异常。

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/6%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84.png" />

## TLB

TLB，Translation Lookaside Buffer：

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这就带来了时间上的开销。所以，在CPU中，加入了一个专门存放程序最常访问的页表项的cache，这个cache就是TLB，通常称为页表缓存，转址旁路缓存，快表。CPU在内存转换时，会先查TLB，如果没找到，才会继续查常规的页目录表。

## 查看内存的使用情况

### free

free显示的是整个系统的内存使用情况。

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/7%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-free.png" />

- total：总内存大小。
- used：已经使用的内存大小，包含了共享内存。
- **free**：未使用内存大小。
- shared：共享内存大小。
- **buff**：通常称为缓冲，是对**磁盘数据**的缓存。既会用在读请求中，也会用在写请求中。内核可以把分散的写集中起来，统一优化。
- **cache**：通常称为缓存，是对**文件数据**的缓存。既会用在读请求中，也会用在写请求中。
- available: 新进程可用的内存大小。available包含free和可回收的缓存。并不是所有缓存都可以回收，因为有些缓存可能正在使用中。可以粗略的认为，**total = used + available**，**available = free + buff/cache**。

### top

top可以显示进程的内存使用情况。

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/memory-manager/8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-top.png" />

- **VIRT**：进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。虚拟内存通常并不会全部分配物理内存，它通常比RES大得多。
- **RES**：常驻内存的大小，也即进程实际使用的物理内存大小，但不包括swap和共享内存。
- **SHR**：共享内存的大小，比如与其他进程共同使用的共享内存，加载的动态链接库等。SHR并不一定是共享的，比如非共享的动态链接库。
- **%MEM**：进程使用的物理内存占系统总内存的百分比。

