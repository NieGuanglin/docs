[TOC]

# 存储系统的分层

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/io-manager/1%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E5%88%86%E5%B1%82.jpg" />

<img src="/Users/nieguanglin/docs/pics/os/io-manager/1存储系统分层.jpg" alt="1存储系统分层.png" style="zoom:100%;" />

## 通用块层

与虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。

## 块设备I/O调度层

对上层发来的I/O请求排队，并通过重新排序，请求合并等方式，提高磁盘读写的效率。

### 调度算法

1. None，不做任何处理，常用在虚拟机中，此时磁盘I/O调度完全由物理机负责。
2. NOOP，先入先出，只做一些最基本的请求合并。
3. CFQ，它为每个进程维护一个I/O调度队列，并按时间片来均匀分布每个进程的I/O请求。类似CFS，CFQ还支持进程I/O的优先级调度。
4. DeadLine，分别为读，写请求创建了不同的I/O队列，可以提高磁盘的吞吐量，确保达到deadline的请求被优先处理。它常用在I/O压力比较重的场景，如数据库等。为了完成这个目标，算法中引入了两类队列，一类队列用来对请求按起始扇区序号进行排序，通过红黑树来组织，称为sort_list，按此队列传输性能会比较高；另一类队列对请求按它们的生成时间进行排序，通过链表来组织，称为fifo_list，并且每一个请求都有一个期限值。

## 缓存

存储系统的I/O，通常是整个系统中最慢的一环。Linux通过多种缓存机制来优化I/O效率。

### cached

为了优化文件访问的性能，会使用页缓存，inode缓存，dentry缓存等多种缓存机制，以减少对下层块设备的直接调用。

### buffer

为了优化块设备的访问效率，会使用缓冲区，来缓存块设备的数据。



# 设备控制器屏蔽设备差异

## 设备控制器

cpu不直接和设备打交道，它们中间有一个叫做设备控制器（Device Control Unit）的组件，例如硬盘有磁盘控制器，USB有USB控制器，显示器有视频控制器。控制器有点像小电脑，它有自己的芯片，类似小cpu，可以执行自己的逻辑；它还有自己的寄存器。cpu可以通过写这些寄存器，向控制器下发指令，通过读这些寄存器，查看控制器对于设备的操作状态。cpu对于寄存器的读写，可比直接控制硬件，要标准和轻松很多。

## 输入输出设备分类

- 块设备，Block Device

  **块设备将信息存储在固定大小的块中，每个块都有自己的地址。硬盘就是常见的块设备。**由于块设备传输的数据量比较大，控制器里往往会有缓冲区。cpu写入缓冲区的数据攒够一部分，才会发给设备。cpu读取的数据，也需要在缓冲区攒够一部分，才拷贝到内存。

- 字符设备，Character Device

  **字符设备发送或接收的是字节流。它不用考虑任何块结构，没有办法寻址。鼠标就是常见的字符设备。**

## DMA机制

- DMA，Direct Memory Access

  设备通过中断的方式通知操作系统操作完成，对于频繁读写数据的磁盘，并不友好，这会导致cpu容易经常被打断，被占用大量的时间。硬件设备DMA控制器，可以使得设备在cpu不参与的情况下，能够自行完成把设备数据放入内存。cpu仅仅需要在数据传输的开始和结束进行干预。

- 工作方式

  1. cpu对DMA控制器下发指令，告诉它要读取多少数据，读完的数据放在内存的某个地方。
  2. DMA控制器向磁盘控制器发出指令，通知它从磁盘读数据到它内部的缓冲区，接着磁盘控制器将缓冲区的数据传输到内存。
  3. 当磁盘控制器把数据传输到内存后，磁盘控制器在总线上发出一个确认成功的信号到DMA控制器。
  4. DMA控制器接收到信号后，发中断通知cpu指令完成，cpu就可以直接用内存里面的数据了。



# 驱动程序屏蔽设备控制器差异

## 驱动程序

虽然设备控制器能够帮操作系统屏蔽很多设备的细节，但由于每种设备的控制器的寄存器，缓冲区等使用模式，指令都不同，所以需要驱动程序屏蔽设备控制器的差异。设备驱动程序中是一些面向设备控制器的代码，不同的设备不同。设备驱动程序有统一的接口，对于操作系统其他部分的代码，可以以同样的接口调用设备驱动程序。

设备控制器不属于操作系统的一部分，但是设备驱动程序属于操作系统的一部分。操作系统的内核代码，可以像调用本地代码一样调用驱动程序的代码，驱动程序负责发出特殊的面向设备控制器的指令。而且**中断处理函数也包括在驱动程序中**。

## 通用块设备层

对于块设备，为了减少不同块设备的差异带来的影响，Linux通过一个统一的通用块层，来管理不同的块设备。通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，主要有两个功能：

- 向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备。
- 通用块层还会给文件系统和应用程序发来的I/O请求排队，接着进行I/O调度，比如对队列重新排序，请求合并等。主要目的是为了提高磁盘读写的效率。



# 文件系统接口屏蔽驱动程序差异

应用程序操作设备，都是基于文件系统的接口。

## devtmpfs

**所有的设备都在/dev目录下创建一个特殊的设备文件。这个设备文件也有inode，但是它不关联到硬盘或任何其他存储介质上的数据，而是建立了与某个设备驱动程序的连接。**

- ls设备文件

  ```bash
  $ ls -l /dev
  crw-r--r--	1	root	kmem	1,		1		Dec 18	14:47	mem
  crw-rw-rw-	1	root	root	1,		3		Dec	18	14:47	null
  crw-rw-rw-	1	root	root	1,		8		Dec	18	14:47	random
  crw-rw-rw-	1	root	root	1,		9		Dec	18	14:47	urandom
  crw-rw-rw-	1	root	root	1,		5		Dec	18	14:47	zero
  brw-rw----	1	root	disk	253,	0		Dec	18	14:47	vda
  brw-rw----	1	root	disk	253,	1		Dec	18	14:47	vda1
  brw-rw----	1	root	disk	253,	16	Dec	18	14:47	vdb
  brw-rw----	1	root	disk	253,	17	Dec	18	14:47	vdb1
  ```

  第一位字符，以c开头表示字符设备，以b开头表示块设备。日期之前的两个数字，一个是主设备号，一个是次设备号。主设备号定位设备驱动程序，次设备号作为参数传给驱动程序，选择相应的单元。

- ls内核模块

  ```bash
  $ lsmod
  Module									Size				Used by
  iptable_mangle					12695				1
  iptable_filter					12810				8
  iptable_nat							12875				1
  nf_nat_ipv4							14115				1 iptable_nat
  ip_tables								27126				3	iptable_filter,iptable_mangle,iptable_nat
  ext4										571716			13
  mbcache									14958				1 ext4
  jbd2										103046			1	ext4
  ```

  Linux的驱动程序已经被写成和操作系统有标准接口的代码，可以看成一个标准的内核模块。在Linux里面，安装驱动程序，其实就是加载一个内核模块。

  lsmod命令，可以查看有没有加载过相应的内核模块。

- 安装驱动

  ```bash
  $ insmod openvswitch.ko
  ```

  如果没有安装过相应的驱动，可以通过insmod安装，内核模块的后缀一般是.ko。比如安装openvswitch的驱动。

- 建立设备文件与驱动程序的连接

  ```bash
  $ mknod filename type major minor
  ```

  有了驱动，就可以通过mknod命令在/dev下创建设备文件。filename就是/dev下的设备名称，type为c就是字符设备，为b就是块设备。 major就是主设备号，minor就是次设备号。一旦执行了命令，新创建的设备文件就和上面加载过的驱动关联起来。就可以通过操作设备文件来操作驱动程序，从而操作设备。

## sysfs

/sys目录下的sysfs文件系统，是一个管理设备的文件系统。它把实际连接到系统上的设备和总线组成了一个分层的文件系统。这个文件系统是当前系统上实际设备数的真实反映。

- /sys/devices

  内核对系统中所有设备的分层次的表示。

- /sys/dev

  该目录下，一个char目录，一个block目录，分别维护一个按字符设备和块设备的主次设备号码（major:minor）链接到真实的设备（/sys/devices）的符号链接文件。

- /sys/block

  系统当前所有的块设备。

- /sys/module

  系统中所有模块的信息。



# 中断

**中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。**

**当设备完成任务，硬件中断控制器会通过中断这种方式来通知cpu，cpu就会保存当前进程的上下文，调用相应的中断处理函数来处理中断，然后从中断返回。从中断返回，是cpu的一个执行进程切换的时机，也就是说这个时候会发生进程调度。**

**与进程调度时保存进程上下文不同，由于中断导致的上下文切换并不涉及到进程的用户态资源，只包括内核态中断服务程序执行所必须的状态，包括cpu寄存器，内核堆栈等。中断完全在内核里面处理完毕。**即便中断打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存等用户态资源。

## 硬中断和软中断

由于中断处理程序会打断其他进程的运行，而且处理中断的过程中会导致中断丢失，所以中断处理程序就需要尽可能快地运行。Linux把中断处理过程分成了上半部和下半部两个阶段，也即硬中断和软中断。

- 上半部用来快速处理中断，在中断禁止模式下运行，主要处理跟硬件紧密相关的工作，或时间敏感的工作。
- 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行，名字为[ksoftirqd/cpu编号]。

/proc/softirqs提供了软中断的运行情况；/proc/interrupts提供了硬中断的运行情况。

## 硬中断与软中断的配合举例

中断的机制应用到网络IO的时候，如果只有硬中断就会比较麻烦。网络包收到后的处理工作，要进行大量的内核协议栈的处理，最终才能放到进程的接收缓冲区中。如果只有硬中断这种方式来处理网络IO，由于硬中断的优先级比较高，这样cpu就会忙于处理大量的网络IO而不能及时响应其他中断事件，导致操作系统实时性变差。

所以需要软中断，来配合硬中断处理网络IO。**硬中断只是收包，很快就完成，这样就不耽误cpu响应其他外部高优先级的中断。而软中断优先级较低，负责将包进行各种处理，从驱动层，到网络协议栈，最终把数据放在接收缓冲区中。**

## 硬中断与软中断的对比

1. 硬中断是由外设引发的，它的中断号是由中断处理器提供的；软中断是执行中断指令产生的，它的中断号是由指令直接指出，无需中断处理器。
2. 硬中断可被屏蔽；软中断不可屏蔽。
3. 硬中断处理程序要确保它能快速地完成任务，称为上半部；软中断处理剩余未完成的工作，属于下半部，这是一种推后执行的机制。

## 接收网络包的中断过程

1. 网络包到来，触发硬中断，调用驱动程序中的中断处理函数，中断暂时关闭。
2. 中断处理函数将当前设备放到poll_list中，触发软中断。硬中断结束，中断重新打开。
3. 在软中断的处理过程中，**主动轮询**poll_list中的设备，使用注册的poll函数处理网络包。

这种触发中断，轮询poll的机制，称为NAPI。

## 中断向量表

为了处理中断，cpu硬件要求每一个cpu都有一个中断向量表，里面记录着每一个中断对应的处理方法。cpu能够处理的中断总共256个。所有的中断都对应一个中断门，设备中断的中断门最终会统一调用IRQ，它就是设备中断的统一入口函数。

- 从0～31的前32位是系统陷入或者系统异常，这些错误无法屏蔽，一定要处理。
- 第32位是32位系统的系统调用。
- 其他的都用于设备中断。

虽然前33位都是固定的，但是后面的设备中断却是各个cpu独立的。也即，中断向量，中断向量表是各个cpu本地有效的。

## 抽象中断层

抽象中断层的主要逻辑，就是从抽象中断信号映射到中断描述结构。

多个cpu，多个中断控制器，每个中断控制器都各有各的物理中断信号，没办法保证虚拟中断信号是连续的，也就是说不适合通过数组来保存中断描述结构。所以，Linux的做法是先将物理中断信号转换为虚拟中断信号，再根据虚拟中断信号找到中断描述结构。为了能够通过虚拟中断信号快速定位中断描述结构，使用基数树来构建映射。物理中断信号是各个cpu本地有效的，而虚拟中断信号和中断描述结构是全局有效的。

### 硬件中断的处理过程

<img src="https://github.com/NieGuanglin/docs/blob/main/pics/os/io-manager/2%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png" />

<img src="/Users/nieguanglin/docs/pics/os/io-manager/2中断处理流程.png" alt="2中断处理流程.png" style="zoom:100%;" />

1. 外部设备给中断控制器发送**物理中断信号**。
2. 中断控制器将物理中断信号转换为**中断向量**interrupt vector，发给各个cpu。
3. 每个cpu都有一个中断向量表，根据中断向量在中断向量表中找到中断门处理函数，硬件中断最终统一调用中断入口函数IRQ。到目前为止，都还是cpu硬件的要求。
4. 在IRQ中，将中断向量转换为抽象中断层的**中断信号**irq，根据irq这个整数，通过基数树找到对应的中断描述结构，然后调用里面的中断处理函数。这时才终于调用到驱动里的中断处理函数。



# 存储的形式

## 对象存储

将文件作为一个完整对象的方式来保存。每一个文件都有一个唯一标识这个对象的key，文件的内容就是value。对象可以分门别类地保存在一个叫做存储空间（bucket）的地方，就像文件夹。对于任何一个文件对象，都可以通过HTTP RESTful API来远程获取对象。

- 由于是简单的key-value模式，当需要保存大容量数据的时候，比较容易根据唯一的key进行横向扩展，所以对象存储能够容纳的数据量往往比较大。在数据中心里面保存文档，视频等是很好的方式。
- 没办法像操作文件一样操作它，而是要将value整个对待。

## 分布式文件系统

使用它和使用本地的文件系统几乎没有什么区别，只不过是通过网络的方式访问远程的文件系统。

- 多个容器能看到统一的文件系统，一个文件写入文件系统，另一个容器能够看到，可以实现共享。
- 分布式文件系统的性能和规模是个矛盾，规模一大性能就难以保证；性能好则规模不会很大，所以不像对象存储一样能够保存海量的数据。

## 分布式块存储

相当于云硬盘，也即存储虚拟化的方式，只不过将盘挂载给容器而不是虚拟机。**块存储没有分布式文件系统这一层，一旦挂载到某一个容器，可以有本地的文件系统。**

- 同样规模的情况下，性能相对分布式文件系统要好。如果为了解决一个容器从一台服务器迁移到另一台服务器，如何保持数据存储的问题，块存储是一个很好的选择。它不用解决多个容器共享数据的问题。
- 一般情况下，不同容器挂载的块存储都是不共享的。